{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade Agreements Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import graph_tool.stats as gt_stats\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import clf, xlabel, ylabel, imshow, colorbar, savefig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')\n",
    "\n",
    "pathpta = os.path.abspath(f'../02 Data/PTA Database')\n",
    "pathcepii = os.path.abspath(f'../02 Data/CEPII')\n",
    "pathmrio = os.path.abspath(f'../../MRIO')\n",
    "pathindicators = os.path.abspath(f'../../GVC 2023/Indicators')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Bilateral agreements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct PTA database with depth measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pta_raw = pd.read_excel(f'{pathpta}/01 Horizontal Depth_bilateral.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pta = pta_raw\n",
    "\n",
    "# list of columns \n",
    "wto_plus = pta.filter(regex=r'^wto_plus_.*_le$').columns.tolist()\n",
    "wto_x =  pta.filter(regex=r'^wto_X_.*_le$').columns.tolist()\n",
    "total = wto_plus + wto_x\n",
    "core = wto_plus + [\"wto_X_competitionpolicy_le\", \n",
    "                   \"wto_X_ipr_le\", \n",
    "                   \"wto_X_investment_le\", \n",
    "                   \"wto_X_movementofcapital_le\"]\n",
    "other_econ = ['wto_X_consumerprotection_le', 'wto_X_dataprotection_le', 'wto_X_agriculture_le', 'wto_X_approxlegis_le',\n",
    "              'wto_X_civilprotection_le', 'wto_X_educationandtraining_le', 'wto_X_energy_le', 'wto_X_financialassistance_le',\n",
    "              'wto_X_industrialcooperation_le', 'wto_X_mining_le', 'wto_X_nuclearsafety_le', 'wto_X_publicadministration_le',\n",
    "              'wto_X_regionalcooperation_le', 'wto_X_sme_le', 'wto_X_statistics_le', 'wto_X_taxation_le']\n",
    "\n",
    "depth_list = {'wto_plus': wto_plus, 'wto_x': wto_x, 'total': total, 'core': core, 'econ':other_econ}\n",
    "\n",
    "# add depth columns\n",
    "for depth in depth_list:\n",
    "    pta['depth_' + str(depth)] = pta.filter(items=depth_list[depth], axis=1).clip(lower=0, upper=1).abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_total</th>\n",
       "      <th>depth_wto_plus</th>\n",
       "      <th>depth_wto_x</th>\n",
       "      <th>depth_core</th>\n",
       "      <th>depth_econ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159,118</td>\n",
       "      <td>159,118</td>\n",
       "      <td>159,118</td>\n",
       "      <td>159,118</td>\n",
       "      <td>159,118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      depth_total depth_wto_plus depth_wto_x depth_core depth_econ\n",
       "count     159,118        159,118     159,118    159,118    159,118\n",
       "mean           23             11          12         13          5\n",
       "std            13              4           9          5          5\n",
       "min             0              0           0          0          0\n",
       "25%            11              8           3         10          0\n",
       "50%            28             12          16         15          5\n",
       "75%            36             14          22         17          9\n",
       "max            44             14          32         18         14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pta[['depth_total', 'depth_wto_plus', 'depth_wto_x', 'depth_core', 'depth_econ']].describe().applymap('{:,.0f}'.format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend PTA database to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade agreements active from 2015 onwards\n",
    "inactive = ['Turkey-EFTA', 'EAEC', 'Nicaragua - Chinese Taipei', 'NAFTA', 'Turkey - Jordan']\n",
    "pta_2015 = pta[(pta['year'] == 2015) & (~pta['agreement'].isin(inactive))]\n",
    "\n",
    "# years to be added \n",
    "add_years = list(range(2016, 2023))\n",
    "\n",
    "# copy columns\n",
    "pta_supplement = pd.DataFrame(columns=pta_2015.columns)\n",
    "\n",
    "# additional rows 2016-2022\n",
    "for year in add_years:\n",
    "    row = pta_2015.copy()\n",
    "    row['year'] = year\n",
    "    pta_supplement = pd.concat([pta_supplement, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pta_full = pd.concat([pta, pta_supplement], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Borin Mancini decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM decomposition 2000, 2007-2022\n",
    "ta_72 = pd.read_parquet(f'{pathindicators}/Trade Accounting/ta.parquet')\n",
    "ta_62 = pd.read_parquet(f'{pathindicators}/Trade Accounting/ta62.parquet')\n",
    "\n",
    "ta_62 = ta_62[ta_62['t'].astype(int) < 2017] # remove 2017 onwards\n",
    "ta_62.loc[ta_62['s'] == 63, 's'], ta_62.loc[ta_62['r'] == 63, 'r'] = 73, 73 # change RoW code\n",
    "\n",
    "ta = pd.concat([ta_62, ta_72], ignore_index=True) # combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate linkage measures\n",
    "ta['REX'] = ta['REX1'] + ta['REX2'] + ta['REX3']\n",
    "ta['REF'] = ta['REF1'] + ta['REF2']\n",
    "\n",
    "ta['DVA'] = ta['DAVAX1'] + ta['DAVAX2'] + ta['REX'] + ta['REF'] # total DVA\n",
    "ta['DVA_int'] = ta['DAVAX2'] + ta['REX'] + ta['REF'] # DVA intermediates \n",
    "ta['DVA_intrex'] = ta['REX'] + ta['REF'] # DVA re-exported\n",
    "\n",
    "ta['PDC'] = ta['PDC1'] + ta['PDC2'] # PDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize country names\n",
    "countries = pd.read_excel(f'{pathmrio}/countries.xlsx').dropna(subset=['mrio'])\n",
    "countries = countries[['iso_a3', 'name_adb', 'region_wb', 'mrio']]\n",
    "countries['mrio'] = countries['mrio'].astype(int)\n",
    "\n",
    "countries_map, iso_map, region_map = dict(zip(countries['mrio'], countries['name_adb'])), dict(zip(countries['mrio'], countries['iso_a3'])), dict(zip(countries['mrio'], countries['region_wb']))\n",
    "\n",
    "ta['source_iso'], ta['source_name'], ta['receive_iso'], ta['receive_name']  = ta['s'].map(iso_map), ta['s'].map(countries_map), ta['r'].map(iso_map), ta['r'].map(countries_map)\n",
    "ta['source_region'], ta['receive_region'] = ta['s'].map(region_map), ta['r'].map(region_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = ta[['t', 'source_iso', 'source_name', 'source_region', 'receive_iso', 'receive_name', 'receive_region', 'Exports', 'DVA', 'DVA_int', 'DVA_intrex', 'FVA', 'PDC']]\n",
    "decomp.loc[:, 't'] = decomp['t'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Gravity model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/n9w0gpv53y72x5k9wk3hp63w0000gn/T/ipykernel_555/2714760110.py:1: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gravity = pd.read_csv(f'{pathcepii}/Gravity_V202211.csv')\n"
     ]
    }
   ],
   "source": [
    "gravity = pd.read_csv(f'{pathcepii}/Gravity_V202211.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = decomp[(decomp['source_iso'] != 'ROW') & (decomp['receive_iso'] != 'ROW')] # remove RoW\n",
    "\n",
    "decomp['partners'] = decomp.apply(lambda row: tuple(sorted([row['source_iso'], row['receive_iso']])), axis=1)\n",
    "pta_full['partners'] = pta_full.apply(lambda row: tuple(sorted([row['iso1'], row['iso2']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_only', 'both']\n",
       "Categories (3, object): ['left_only', 'right_only', 'both']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = decomp.merge(pta_full, left_on=['partners', 't'], right_on=['partners', 'year'], how='left', indicator=True) # merge decomp and pta dfs \n",
    "merged['_merge'].unique() # check values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(gravity, left_on=['source_iso', 'receive_iso', 't'], right_on=['iso3_o', 'iso3_d', 'year'], how='left') # merge with gravity df\n",
    "merged.to_parquet('data/01_merged data full.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Kazakhstan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaz = merged[(merged['source_iso'] == 'KAZ')]\n",
    "kaz.to_parquet('data/02_merged data kazakhstan.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvc-pta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
